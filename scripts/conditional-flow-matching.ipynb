{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4e68e6-508a-4ac7-9579-36c5f0808fa3",
   "metadata": {},
   "source": [
    "\n",
    "BACKEND part should be run or the geomstats does not convert correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7443040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GEOMSTATS_BACKEND=pytorch\n"
     ]
    }
   ],
   "source": [
    "%env GEOMSTATS_BACKEND=pytorch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import trimesh\n",
    "import pyrender\n",
    "import numpy as np\n",
    "import glob \n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0252df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "from geomstats.geometry.special_orthogonal import SpecialOrthogonal\n",
    "\n",
    "# from utils.plotting import plot_so3\n",
    "# from utils.optimal_transport import so3_wasserstein as wasserstein\n",
    "# from FoldFlow.foldflow.utils.so3_helpers import norm_SO3, expmap\n",
    "# from FoldFlow.foldflow.utils.so3_condflowmatcher import SO3ConditionalFlowMatcher\n",
    "# from FoldFlow.so3_experiments.models.models import PMLP\n",
    "\n",
    "from so3_helpers import norm_SO3, expmap\n",
    "from so3_condflowmatcher import SO3ConditionalFlowMatcher\n",
    "from models import PMLP\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "# from data.datasets import SpecialOrthogonalGroup\n",
    "\n",
    "from geomstats._backend import _backend_config as _config\n",
    "_config.DEFAULT_DTYPE = torch.cuda.FloatTensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83d3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "so3_group = SpecialOrthogonal(n=3, point_type=\"matrix\")\n",
    "FM = SO3ConditionalFlowMatcher(manifold=so3_group)\n",
    "def loss_fn(v, u, x):\n",
    "    res = v - u\n",
    "    norm = norm_SO3(x, res) # norm-squared on SO(3)\n",
    "    loss = torch.mean(norm, dim=-1)\n",
    "    return loss\n",
    "\n",
    "dim = 9 # network ouput is 9 dimensional (3x3 matrix)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# MLP with a projection at the end, projection on to the tanget space of the manifold\n",
    "model = PMLP(dim=dim, time_varying=True).to(device)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# ODE inference on SO(3)\n",
    "def inference(model, xt, t, dt):\n",
    "    with torch.no_grad():\n",
    "        vt = model(torch.cat([xt, t[:, None]], dim=-1)) # vt on the tanget of xt\n",
    "        vt = rearrange(vt, 'b (c d) -> b c d', c=3, d=3)\n",
    "        xt = rearrange(xt, 'b (c d) -> b c d', c=3, d=3)\n",
    "        xt_new = expmap(xt, vt * dt)                   # expmap to get the next point\n",
    "    return rearrange(xt_new, 'b c d -> b (c d)', c=3, d=3)\n",
    "# def inference_recursive(model, x_0, steps=100, device='cuda'):\n",
    "#     t = torch.linspace(0, 1, steps).to(device)\n",
    "#     def ode_func(t, xt,dt):\n",
    "#         # Reshape t to match model input expectations\n",
    "#         t_batch = torch.full((x.shape[0], 1), t.item(), device=device)\n",
    "#         with torch.no_grad():\n",
    "#             vt = model(torch.cat([xt, t[:, None]], dim=-1)) # vt on the tanget of xt\n",
    "#             vt = rearrange(vt, 'b (c d) -> b c d', c=3, d=3)\n",
    "#             xt = rearrange(xt, 'b (c d) -> b c d', c=3, d=3)\n",
    "#             xt_new = expmap(xt, vt * dt)                   # expmap to get the next point\n",
    "#         return rearrange(xt_new, 'b c d -> b (c d)', c=3, d=3)\n",
    "#         #return flow_model(x, t_batch)\n",
    "#     # Integrate from t=0 to t=1\n",
    "#     trajectory = odeint(\n",
    "#         ode_func,\n",
    "#         x_0,\n",
    "#         t,\n",
    "#         method='rk4'  # You can also try 'dopri5' for adaptive stepping\n",
    "#     )\n",
    "    \n",
    "#     return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811f038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example obj:  data/meshes/CerealBox/a61cd12446207107d59ff053d1480d84.obj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meshes = glob.glob(\"data/meshes/**/*.obj\")\n",
    "grasps = glob.glob(\"data/grasps/*.h5\")\n",
    "example_obj= meshes[0]\n",
    "example_grasp = grasps[0]\n",
    "\n",
    "\n",
    "example_obj_id = example_obj.split(\"/\")[-1].split(\".\")[0]\n",
    "print(\"Example obj: \", example_obj)\n",
    "\n",
    "corresponding_grasps = [grasp for grasp in grasps if example_obj_id in grasp][0]\n",
    "\n",
    "with h5py.File(example_grasp, 'r') as h5file:\n",
    "    grasp_T = h5file['grasps']['transforms'][0,:,:]\n",
    "grasp_T = torch.tensor(grasp_T).unsqueeze(0).float()\n",
    "grasp_T.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d6e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraspDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        so3_part = self.data[idx][:3,:3]\n",
    "        translational_part = self.data[idx][:3,3]\n",
    "        return so3_part, translational_part\n",
    "    \n",
    "grasp_dataset = GraspDataset(grasp_T.double())\n",
    "trainloader = DataLoader(grasp_dataset, batch_size=100, shuffle=True)\n",
    "testset = DataLoader(grasp_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ae9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [01:25<00:00, 11.73it/s, Epoch=999, Loss=0.0735, Avg Loss=0.0735]\n"
     ]
    }
   ],
   "source": [
    "def main_loop(model, optimizer, num_epochs=150, display=True):\n",
    "    losses = []\n",
    "    global_step = 0\n",
    "    \n",
    "    # Create a single progress bar for all epochs\n",
    "    with tqdm(total=num_epochs * len(trainloader), desc=\"Training\") as global_progress_bar:\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_losses = []\n",
    "            \n",
    "            if (epoch % 10) == 0:\n",
    "                n_test = len(testset.dataset)\n",
    "                traj = torch.tensor(Rotation.random(n_test).as_matrix()).to(device).reshape(-1, 9)\n",
    "                for t in torch.linspace(0, 1, 200):\n",
    "                    t = torch.tensor([t]).to(device).repeat(n_test).requires_grad_(True)\n",
    "                    dt = torch.tensor([1/200]).to(device)\n",
    "                    traj = inference(model, traj, t, dt)\n",
    "                final_traj = rearrange(traj, 'b (c d) -> b c d', c=3, d=3)\n",
    "            \n",
    "            for _, (so3_data, trnslt_part) in enumerate(trainloader):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Repeat the data if needed\n",
    "                so3_data = so3_data.repeat(1000, 1, 1)\n",
    "                x1 = so3_data.to(device).double()\n",
    "                x0 = torch.tensor(Rotation.random(x1.size(0)).as_matrix(), dtype=torch.float64).to(device)\n",
    "                \n",
    "                t, xt, ut = FM.sample_location_and_conditional_flow_simple(x0, x1)\n",
    "                \n",
    "                vt = model(torch.cat([rearrange(xt, 'b c d -> b (c d)', c=3, d=3), t[:, None]], dim=-1))\n",
    "                vt = rearrange(vt, 'b (c d) -> b c d', c=3, d=3)\n",
    "                \n",
    "                loss = loss_fn(vt, ut, xt)\n",
    "                epoch_losses.append(loss.detach().item())\n",
    "                losses.append(loss.detach().cpu().numpy())\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update the global progress bar\n",
    "                global_progress_bar.update(1)\n",
    "                global_progress_bar.set_postfix({\n",
    "                    'Epoch': epoch, \n",
    "                    'Loss': f'{loss.item():.4f}', \n",
    "                    'Avg Loss': f'{np.mean(epoch_losses):.4f}'\n",
    "                })\n",
    "                \n",
    "                global_step += 1\n",
    "    \n",
    "    return model, np.array(losses)\n",
    "\n",
    "# Run training\n",
    "model, losses = main_loop(model, optimizer, num_epochs=1000, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ffb578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3679, -0.3304,  0.8692],\n",
       "          [-0.1471,  0.9437,  0.2964],\n",
       "          [-0.9181, -0.0188, -0.3958]]], dtype=torch.float64),\n",
       " tensor([[[-0.3808, -0.3274,  0.8647, -0.2228],\n",
       "          [-0.1488,  0.9447,  0.2922, -0.1666],\n",
       "          [-0.9126, -0.0174, -0.4085,  0.1002]]], dtype=torch.float64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test = len(grasp_dataset)\n",
    "traj = torch.tensor(Rotation.random(n_test).as_matrix()).to(device).reshape(-1, 9)\n",
    "for t in torch.linspace(0, 1, 200):\n",
    "    t = torch.tensor([t]).to(device).repeat(n_test)\n",
    "    dt = torch.tensor([1/200]).to(device)\n",
    "    traj = inference(model, traj, t, dt)\n",
    "final_traj = rearrange(traj, 'b (c d) -> b c d', c=3, d=3)\n",
    "final_traj,grasp_dataset.data[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa0c4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE3VelocityField(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=64): #trial for translation \n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim + 1, hidden_dim),  # Include time t as dim+1\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)  # 3 for translation, we will implement SO3 later rt = expr0(tlogr0(r1)) with linalg inverse \n",
    "        )\n",
    "\n",
    "    def forward(self, T, t):\n",
    "        #T_flat = T.view(T.shape[0], -1)  # Flatten T\n",
    "        input_data = torch.cat([T,t ], dim=1)\n",
    "        return self.net(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a2edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 1.0490559339523315\n",
      "Epoch: 100 0.18860095739364624\n",
      "Epoch: 200 0.17464306950569153\n",
      "Epoch: 300 0.14537473022937775\n",
      "Epoch: 400 0.10317289084196091\n",
      "Epoch: 500 0.09229150414466858\n",
      "Epoch: 600 0.09045705199241638\n",
      "Epoch: 700 0.07828841358423233\n",
      "Epoch: 800 0.07142215222120285\n",
      "Epoch: 900 0.06375863403081894\n",
      "Epoch: 1000 0.06571261584758759\n",
      "Epoch: 1100 0.055483411997556686\n",
      "Epoch: 1200 0.05109038203954697\n",
      "Epoch: 1300 0.05603230372071266\n",
      "Epoch: 1400 0.04873558506369591\n",
      "Epoch: 1500 0.04899878799915314\n",
      "Epoch: 1600 0.049523208290338516\n",
      "Epoch: 1700 0.05539128556847572\n",
      "Epoch: 1800 0.04877127707004547\n",
      "Epoch: 1900 0.05637989193201065\n",
      "Epoch: 2000 0.04719003662467003\n",
      "Epoch: 2100 0.03758149594068527\n",
      "Epoch: 2200 0.04356033727526665\n",
      "Epoch: 2300 0.034619301557540894\n",
      "Epoch: 2400 0.040414467453956604\n",
      "Epoch: 2500 0.034439023584127426\n",
      "Epoch: 2600 0.036813341081142426\n",
      "Epoch: 2700 0.0403117835521698\n",
      "Epoch: 2800 0.03305071219801903\n",
      "Epoch: 2900 0.031559381633996964\n",
      "Epoch: 3000 0.030370160937309265\n",
      "Epoch: 3100 0.03542419523000717\n",
      "Epoch: 3200 0.03291263431310654\n",
      "Epoch: 3300 0.028820233419537544\n",
      "Epoch: 3400 0.02579530142247677\n",
      "Epoch: 3500 0.02736734040081501\n",
      "Epoch: 3600 0.030554793775081635\n",
      "Epoch: 3700 0.0269700326025486\n",
      "Epoch: 3800 0.02913738414645195\n",
      "Epoch: 3900 0.025446614250540733\n",
      "Epoch: 4000 0.022992096841335297\n",
      "Epoch: 4100 0.02634240686893463\n",
      "Epoch: 4200 0.01972256787121296\n",
      "Epoch: 4300 0.02327784150838852\n",
      "Epoch: 4400 0.021463630720973015\n",
      "Epoch: 4500 0.02758120559155941\n",
      "Epoch: 4600 0.023329386487603188\n",
      "Epoch: 4700 0.023753345012664795\n",
      "Epoch: 4800 0.019559845328330994\n",
      "Epoch: 4900 0.019467880949378014\n",
      "Epoch: 5000 0.02370835840702057\n",
      "Epoch: 5100 0.0256655290722847\n",
      "Epoch: 5200 0.03355442360043526\n",
      "Epoch: 5300 0.01728891022503376\n",
      "Epoch: 5400 0.016684310510754585\n",
      "Epoch: 5500 0.029899267479777336\n",
      "Epoch: 5600 0.02828826569020748\n",
      "Epoch: 5700 0.017278874292969704\n",
      "Epoch: 5800 0.018247421830892563\n",
      "Epoch: 5900 0.02687474898993969\n",
      "Epoch: 6000 0.019113978371024132\n",
      "Epoch: 6100 0.021014174446463585\n",
      "Epoch: 6200 0.017350999638438225\n",
      "Epoch: 6300 0.016690630465745926\n",
      "Epoch: 6400 0.02403201349079609\n",
      "Epoch: 6500 0.014783709309995174\n",
      "Epoch: 6600 0.017870808020234108\n",
      "Epoch: 6700 0.017179852351546288\n",
      "Epoch: 6800 0.024087702855467796\n",
      "Epoch: 6900 0.023747451603412628\n",
      "Epoch: 7000 0.024927454069256783\n",
      "Epoch: 7100 0.023468371480703354\n",
      "Epoch: 7200 0.00969027355313301\n",
      "Epoch: 7300 0.021157078444957733\n",
      "Epoch: 7400 0.021804941818118095\n",
      "Epoch: 7500 0.01520155556499958\n",
      "Epoch: 7600 0.016656775027513504\n",
      "Epoch: 7700 0.019120315089821815\n",
      "Epoch: 7800 0.02403419278562069\n",
      "Epoch: 7900 0.019416730850934982\n",
      "Epoch: 8000 0.031678564846515656\n",
      "Epoch: 8100 0.018813539296388626\n",
      "Epoch: 8200 0.015037203207612038\n",
      "Epoch: 8300 0.016512569040060043\n",
      "Epoch: 8400 0.017334463074803352\n",
      "Epoch: 8500 0.013152463361620903\n",
      "Epoch: 8600 0.023197965696454048\n",
      "Epoch: 8700 0.01785571500658989\n",
      "Epoch: 8800 0.01546495035290718\n",
      "Epoch: 8900 0.015738317742943764\n",
      "Epoch: 9000 0.0096912095323205\n",
      "Epoch: 9100 0.010392753407359123\n",
      "Epoch: 9200 0.011028398759663105\n",
      "Epoch: 9300 0.013504442758858204\n",
      "Epoch: 9400 0.015835409983992577\n",
      "Epoch: 9500 0.0274993646889925\n",
      "Epoch: 9600 0.017670530825853348\n",
      "Epoch: 9700 0.015011964365839958\n",
      "Epoch: 9800 0.016189493238925934\n",
      "Epoch: 9900 0.014233042486011982\n",
      "Epoch: 10000 0.016273915767669678\n",
      "Epoch: 10100 0.017962483689188957\n",
      "Epoch: 10200 0.010754384100437164\n",
      "Epoch: 10300 0.0129215307533741\n",
      "Epoch: 10400 0.018471794202923775\n",
      "Epoch: 10500 0.021480172872543335\n",
      "Epoch: 10600 0.021691448986530304\n",
      "Epoch: 10700 0.0148822832852602\n",
      "Epoch: 10800 0.01784714125096798\n",
      "Epoch: 10900 0.014347216114401817\n",
      "Epoch: 11000 0.016632797196507454\n",
      "Epoch: 11100 0.01308016199618578\n",
      "Epoch: 11200 0.008736735209822655\n",
      "Epoch: 11300 0.011743530631065369\n",
      "Epoch: 11400 0.01198254432529211\n",
      "Epoch: 11500 0.02118820697069168\n",
      "Epoch: 11600 0.010275822132825851\n",
      "Epoch: 11700 0.01884452998638153\n",
      "Epoch: 11800 0.016413157805800438\n",
      "Epoch: 11900 0.016324510797858238\n",
      "Epoch: 12000 0.015014449134469032\n",
      "Epoch: 12100 0.011975699104368687\n",
      "Epoch: 12200 0.014204454608261585\n",
      "Epoch: 12300 0.020330151543021202\n",
      "Epoch: 12400 0.015549253672361374\n",
      "Epoch: 12500 0.013073096983134747\n",
      "Epoch: 12600 0.01725938729941845\n",
      "Epoch: 12700 0.013493872247636318\n",
      "Epoch: 12800 0.019142210483551025\n",
      "Epoch: 12900 0.017792582511901855\n",
      "Epoch: 13000 0.02231532335281372\n",
      "Epoch: 13100 0.013597376644611359\n",
      "Epoch: 13200 0.015423162840306759\n",
      "Epoch: 13300 0.013537319377064705\n",
      "Epoch: 13400 0.014365282841026783\n",
      "Epoch: 13500 0.014614944346249104\n",
      "Epoch: 13600 0.010784998536109924\n",
      "Epoch: 13700 0.010648543946444988\n",
      "Epoch: 13800 0.01611911505460739\n",
      "Epoch: 13900 0.019909759983420372\n",
      "Epoch: 14000 0.015081079676747322\n",
      "Epoch: 14100 0.016940826550126076\n",
      "Epoch: 14200 0.01138069573789835\n",
      "Epoch: 14300 0.011783367022871971\n",
      "Epoch: 14400 0.0063262260518968105\n",
      "Epoch: 14500 0.010045100934803486\n",
      "Epoch: 14600 0.014871645718812943\n",
      "Epoch: 14700 0.013548975810408592\n",
      "Epoch: 14800 0.012207192368805408\n",
      "Epoch: 14900 0.017332445830106735\n",
      "Epoch: 15000 0.030382314696907997\n",
      "Epoch: 15100 0.015117373317480087\n",
      "Epoch: 15200 0.01060958206653595\n",
      "Epoch: 15300 0.013347099535167217\n",
      "Epoch: 15400 0.0075029716826975346\n",
      "Epoch: 15500 0.011810480616986752\n",
      "Epoch: 15600 0.014112615957856178\n",
      "Epoch: 15700 0.013324066996574402\n",
      "Epoch: 15800 0.013172214850783348\n",
      "Epoch: 15900 0.011259670369327068\n",
      "Epoch: 16000 0.012011174112558365\n",
      "Epoch: 16100 0.009635303169488907\n",
      "Epoch: 16200 0.012158721685409546\n",
      "Epoch: 16300 0.014086149632930756\n",
      "Epoch: 16400 0.011333933100104332\n",
      "Epoch: 16500 0.006428782362490892\n",
      "Epoch: 16600 0.010590585879981518\n",
      "Epoch: 16700 0.011572868563234806\n",
      "Epoch: 16800 0.00919330958276987\n",
      "Epoch: 16900 0.014991198666393757\n",
      "Epoch: 17000 0.009532565250992775\n",
      "Epoch: 17100 0.01441263034939766\n",
      "Epoch: 17200 0.01565380021929741\n",
      "Epoch: 17300 0.011767781339585781\n",
      "Epoch: 17400 0.008390350267291069\n",
      "Epoch: 17500 0.012165926396846771\n",
      "Epoch: 17600 0.012237775139510632\n",
      "Epoch: 17700 0.013667027465999126\n",
      "Epoch: 17800 0.01196111086755991\n",
      "Epoch: 17900 0.0085603017359972\n",
      "Epoch: 18000 0.011029092594981194\n",
      "Epoch: 18100 0.009729541838169098\n",
      "Epoch: 18200 0.012257806956768036\n",
      "Epoch: 18300 0.014255652204155922\n",
      "Epoch: 18400 0.011066019535064697\n",
      "Epoch: 18500 0.012103467248380184\n",
      "Epoch: 18600 0.006911277770996094\n",
      "Epoch: 18700 0.009135455824434757\n",
      "Epoch: 18800 0.013481760397553444\n",
      "Epoch: 18900 0.009383470751345158\n",
      "Epoch: 19000 0.0115538090467453\n",
      "Epoch: 19100 0.010862653143703938\n",
      "Epoch: 19200 0.009539306163787842\n",
      "Epoch: 19300 0.01449482049793005\n",
      "Epoch: 19400 0.00877724401652813\n",
      "Epoch: 19500 0.011293139308691025\n",
      "Epoch: 19600 0.009818360209465027\n",
      "Epoch: 19700 0.01586155779659748\n",
      "Epoch: 19800 0.007126192096620798\n",
      "Epoch: 19900 0.00791893620043993\n",
      "Epoch: 20000 0.011005123145878315\n",
      "Epoch: 20100 0.018894383683800697\n",
      "Epoch: 20200 0.008524131961166859\n",
      "Epoch: 20300 0.008730405941605568\n",
      "Epoch: 20400 0.012523084878921509\n",
      "Epoch: 20500 0.013384686782956123\n",
      "Epoch: 20600 0.009817167185246944\n",
      "Epoch: 20700 0.005652184132486582\n",
      "Epoch: 20800 0.010948222130537033\n",
      "Epoch: 20900 0.019612682983279228\n",
      "Epoch: 21000 0.01481806579977274\n",
      "Epoch: 21100 0.009887494146823883\n",
      "Epoch: 21200 0.01062031090259552\n",
      "Epoch: 21300 0.00890499260276556\n",
      "Epoch: 21400 0.011186739429831505\n",
      "Epoch: 21500 0.009196621365845203\n",
      "Epoch: 21600 0.009282050654292107\n",
      "Epoch: 21700 0.010934453457593918\n",
      "Epoch: 21800 0.01436606701463461\n",
      "Epoch: 21900 0.013498125597834587\n",
      "Epoch: 22000 0.007066916208714247\n",
      "Epoch: 22100 0.013984655030071735\n",
      "Epoch: 22200 0.01357897650450468\n",
      "Epoch: 22300 0.009888648986816406\n",
      "Epoch: 22400 0.009307597763836384\n",
      "Epoch: 22500 0.013866241089999676\n",
      "Epoch: 22600 0.010696818120777607\n",
      "Epoch: 22700 0.008510131388902664\n",
      "Epoch: 22800 0.008876850828528404\n",
      "Epoch: 22900 0.008234551176428795\n",
      "Epoch: 23000 0.012001674622297287\n",
      "Epoch: 23100 0.01173955574631691\n",
      "Epoch: 23200 0.012541931122541428\n",
      "Epoch: 23300 0.01112859882414341\n",
      "Epoch: 23400 0.009773755446076393\n",
      "Epoch: 23500 0.009063377976417542\n",
      "Epoch: 23600 0.012649991549551487\n",
      "Epoch: 23700 0.01308114267885685\n",
      "Epoch: 23800 0.009277359582483768\n",
      "Epoch: 23900 0.01414179615676403\n",
      "Epoch: 24000 0.007618809584528208\n",
      "Epoch: 24100 0.009146658703684807\n",
      "Epoch: 24200 0.007401498034596443\n",
      "Epoch: 24300 0.007494958117604256\n",
      "Epoch: 24400 0.012053316459059715\n",
      "Epoch: 24500 0.01623743772506714\n",
      "Epoch: 24600 0.007181971333920956\n",
      "Epoch: 24700 0.013874934986233711\n",
      "Epoch: 24800 0.008619514293968678\n",
      "Epoch: 24900 0.013748317956924438\n",
      "Epoch: 25000 0.011607821099460125\n",
      "Epoch: 25100 0.016569141298532486\n",
      "Epoch: 25200 0.009950356557965279\n",
      "Epoch: 25300 0.01570081152021885\n",
      "Epoch: 25400 0.01457429863512516\n",
      "Epoch: 25500 0.00842250045388937\n",
      "Epoch: 25600 0.008985556662082672\n",
      "Epoch: 25700 0.007863868959248066\n",
      "Epoch: 25800 0.01184079609811306\n",
      "Epoch: 25900 0.010874606668949127\n",
      "Epoch: 26000 0.013497940264642239\n",
      "Epoch: 26100 0.006884315516799688\n",
      "Epoch: 26200 0.009685314260423183\n",
      "Epoch: 26300 0.008890341967344284\n",
      "Epoch: 26400 0.008184920996427536\n",
      "Epoch: 26500 0.01162375882267952\n",
      "Epoch: 26600 0.010859942063689232\n",
      "Epoch: 26700 0.009930111467838287\n",
      "Epoch: 26800 0.008738751523196697\n",
      "Epoch: 26900 0.013548697344958782\n",
      "Epoch: 27000 0.011645772494375706\n",
      "Epoch: 27100 0.013091358356177807\n",
      "Epoch: 27200 0.00633920356631279\n",
      "Epoch: 27300 0.013982565142214298\n",
      "Epoch: 27400 0.00968096498399973\n",
      "Epoch: 27500 0.011892816983163357\n",
      "Epoch: 27600 0.008915313519537449\n",
      "Epoch: 27700 0.011582495644688606\n",
      "Epoch: 27800 0.013104896992444992\n",
      "Epoch: 27900 0.009827870875597\n",
      "Epoch: 28000 0.0068360320292413235\n",
      "Epoch: 28100 0.008576581254601479\n",
      "Epoch: 28200 0.008108331821858883\n",
      "Epoch: 28300 0.01834467612206936\n",
      "Epoch: 28400 0.009870357811450958\n",
      "Epoch: 28500 0.011263023130595684\n",
      "Epoch: 28600 0.006013715174049139\n",
      "Epoch: 28700 0.00805925577878952\n",
      "Epoch: 28800 0.009426345117390156\n",
      "Epoch: 28900 0.009361784905195236\n",
      "Epoch: 29000 0.008962808176875114\n",
      "Epoch: 29100 0.015208998695015907\n",
      "Epoch: 29200 0.009359320625662804\n",
      "Epoch: 29300 0.006359984166920185\n",
      "Epoch: 29400 0.0110270194709301\n",
      "Epoch: 29500 0.0134481992572546\n",
      "Epoch: 29600 0.011227807030081749\n",
      "Epoch: 29700 0.008064331486821175\n",
      "Epoch: 29800 0.006753365974873304\n",
      "Epoch: 29900 0.009052161127328873\n",
      "Epoch: 30000 0.006928524002432823\n",
      "Epoch: 30100 0.013170638121664524\n",
      "Epoch: 30200 0.0048188334330916405\n",
      "Epoch: 30300 0.012246007099747658\n",
      "Epoch: 30400 0.004781229887157679\n",
      "Epoch: 30500 0.010159297846257687\n",
      "Epoch: 30600 0.007914870977401733\n",
      "Epoch: 30700 0.010731734335422516\n",
      "Epoch: 30800 0.011818726547062397\n",
      "Epoch: 30900 0.012701816856861115\n",
      "Epoch: 31000 0.004676413722336292\n",
      "Epoch: 31100 0.008702612482011318\n",
      "Epoch: 31200 0.0075986627489328384\n",
      "Epoch: 31300 0.005033405497670174\n",
      "Epoch: 31400 0.006904433481395245\n",
      "Epoch: 31500 0.011695119552314281\n",
      "Epoch: 31600 0.008947738446295261\n",
      "Epoch: 31700 0.010097019374370575\n",
      "Epoch: 31800 0.007815372198820114\n",
      "Epoch: 31900 0.009288962930440903\n",
      "Epoch: 32000 0.01574605517089367\n",
      "Epoch: 32100 0.010114478878676891\n",
      "Epoch: 32200 0.008150983601808548\n",
      "Epoch: 32300 0.0072032189927995205\n",
      "Epoch: 32400 0.00771131319925189\n",
      "Epoch: 32500 0.0060471585020422935\n",
      "Epoch: 32600 0.009103705175220966\n",
      "Epoch: 32700 0.007870558649301529\n",
      "Epoch: 32800 0.011726956814527512\n",
      "Epoch: 32900 0.007887428626418114\n",
      "Epoch: 33000 0.01290165726095438\n",
      "Epoch: 33100 0.007370011415332556\n",
      "Epoch: 33200 0.014092937111854553\n",
      "Epoch: 33300 0.00578864011913538\n",
      "Epoch: 33400 0.006239357404410839\n",
      "Epoch: 33500 0.009218930266797543\n",
      "Epoch: 33600 0.009391811676323414\n",
      "Epoch: 33700 0.009337028488516808\n",
      "Epoch: 33800 0.008138725534081459\n",
      "Epoch: 33900 0.012296265922486782\n",
      "Epoch: 34000 0.007794579956680536\n",
      "Epoch: 34100 0.006544818170368671\n",
      "Epoch: 34200 0.00478834193199873\n",
      "Epoch: 34300 0.011870119720697403\n",
      "Epoch: 34400 0.008523711934685707\n",
      "Epoch: 34500 0.009913036599755287\n",
      "Epoch: 34600 0.009442874230444431\n",
      "Epoch: 34700 0.009577574208378792\n",
      "Epoch: 34800 0.00548221729695797\n",
      "Epoch: 34900 0.010039584711194038\n",
      "Epoch: 35000 0.010659872554242611\n",
      "Epoch: 35100 0.0118866553530097\n",
      "Epoch: 35200 0.004760933108627796\n",
      "Epoch: 35300 0.009451586753129959\n",
      "Epoch: 35400 0.0060061560943722725\n",
      "Epoch: 35500 0.007306824438273907\n",
      "Epoch: 35600 0.00875056441873312\n",
      "Epoch: 35700 0.009788842871785164\n",
      "Epoch: 35800 0.00701055396348238\n",
      "Epoch: 35900 0.005828878842294216\n",
      "Epoch: 36000 0.006946314591914415\n",
      "Epoch: 36100 0.008374943397939205\n",
      "Epoch: 36200 0.015196507796645164\n",
      "Epoch: 36300 0.004948457702994347\n",
      "Epoch: 36400 0.010143706575036049\n",
      "Epoch: 36500 0.0067274062894284725\n",
      "Epoch: 36600 0.00833095796406269\n",
      "Epoch: 36700 0.007860960438847542\n",
      "Epoch: 36800 0.013727775774896145\n",
      "Epoch: 36900 0.004940076731145382\n",
      "Epoch: 37000 0.010308686643838882\n",
      "Epoch: 37100 0.005853177979588509\n",
      "Epoch: 37200 0.007035617250949144\n",
      "Epoch: 37300 0.007394926622509956\n",
      "Epoch: 37400 0.013663260266184807\n",
      "Epoch: 37500 0.006507961079478264\n",
      "Epoch: 37600 0.013509913347661495\n",
      "Epoch: 37700 0.005813478957861662\n",
      "Epoch: 37800 0.013185838237404823\n",
      "Epoch: 37900 0.00921216793358326\n",
      "Epoch: 38000 0.008242116309702396\n",
      "Epoch: 38100 0.0066319978795945644\n",
      "Epoch: 38200 0.009288857690989971\n",
      "Epoch: 38300 0.008365841582417488\n",
      "Epoch: 38400 0.010748867876827717\n",
      "Epoch: 38500 0.005416163243353367\n",
      "Epoch: 38600 0.009866923093795776\n",
      "Epoch: 38700 0.009774967096745968\n",
      "Epoch: 38800 0.00642306637018919\n",
      "Epoch: 38900 0.008349779061973095\n",
      "Epoch: 39000 0.00519048934802413\n",
      "Epoch: 39100 0.009116274304687977\n",
      "Epoch: 39200 0.004843527916818857\n",
      "Epoch: 39300 0.007332629524171352\n",
      "Epoch: 39400 0.010915720835328102\n",
      "Epoch: 39500 0.008306201547384262\n",
      "Epoch: 39600 0.007203247863799334\n",
      "Epoch: 39700 0.008225489407777786\n",
      "Epoch: 39800 0.006885339040309191\n",
      "Epoch: 39900 0.008226853795349598\n",
      "Epoch: 40000 0.0054765683598816395\n",
      "Epoch: 40100 0.006959615740925074\n",
      "Epoch: 40200 0.010885622352361679\n",
      "Epoch: 40300 0.008869027718901634\n",
      "Epoch: 40400 0.010504196397960186\n",
      "Epoch: 40500 0.0055189551785588264\n",
      "Epoch: 40600 0.009717258624732494\n",
      "Epoch: 40700 0.008089741691946983\n",
      "Epoch: 40800 0.006559576839208603\n",
      "Epoch: 40900 0.0059834993444383144\n",
      "Epoch: 41000 0.006465899758040905\n",
      "Epoch: 41100 0.013418267481029034\n",
      "Epoch: 41200 0.006593122612684965\n",
      "Epoch: 41300 0.011952651664614677\n",
      "Epoch: 41400 0.007197535131126642\n",
      "Epoch: 41500 0.018531661480665207\n",
      "Epoch: 41600 0.009997830726206303\n",
      "Epoch: 41700 0.00812313612550497\n",
      "Epoch: 41800 0.008091787807643414\n",
      "Epoch: 41900 0.009857392869889736\n",
      "Epoch: 42000 0.007958929985761642\n",
      "Epoch: 42100 0.008760003373026848\n",
      "Epoch: 42200 0.00553023349493742\n",
      "Epoch: 42300 0.010683488100767136\n",
      "Epoch: 42400 0.006553569342941046\n",
      "Epoch: 42500 0.006360599305480719\n",
      "Epoch: 42600 0.009104926139116287\n",
      "Epoch: 42700 0.009922699071466923\n",
      "Epoch: 42800 0.00867959763854742\n",
      "Epoch: 42900 0.011505457572638988\n",
      "Epoch: 43000 0.005724121816456318\n",
      "Epoch: 43100 0.007428343407809734\n",
      "Epoch: 43200 0.005967407021671534\n",
      "Epoch: 43300 0.011472937650978565\n",
      "Epoch: 43400 0.004787113517522812\n",
      "Epoch: 43500 0.006023038644343615\n",
      "Epoch: 43600 0.0068245758302509785\n",
      "Epoch: 43700 0.009737526066601276\n",
      "Epoch: 43800 0.006321308668702841\n",
      "Epoch: 43900 0.006564843002706766\n",
      "Epoch: 44000 0.00917187798768282\n",
      "Epoch: 44100 0.0061114756390452385\n",
      "Epoch: 44200 0.008023410104215145\n",
      "Epoch: 44300 0.005809992551803589\n",
      "Epoch: 44400 0.007815372198820114\n",
      "Epoch: 44500 0.005626150872558355\n",
      "Epoch: 44600 0.008860593661665916\n",
      "Epoch: 44700 0.008310943841934204\n",
      "Epoch: 44800 0.00786261260509491\n",
      "Epoch: 44900 0.009408993646502495\n",
      "Epoch: 45000 0.00950733944773674\n",
      "Epoch: 45100 0.006522579118609428\n",
      "Epoch: 45200 0.007239220198243856\n",
      "Epoch: 45300 0.0068406276404857635\n",
      "Epoch: 45400 0.009695718064904213\n",
      "Epoch: 45500 0.01148262806236744\n",
      "Epoch: 45600 0.008647849783301353\n",
      "Epoch: 45700 0.01211700402200222\n",
      "Epoch: 45800 0.010938898660242558\n",
      "Epoch: 45900 0.007959472946822643\n",
      "Epoch: 46000 0.005594654940068722\n",
      "Epoch: 46100 0.005762036424130201\n",
      "Epoch: 46200 0.004720817785710096\n",
      "Epoch: 46300 0.005660700611770153\n",
      "Epoch: 46400 0.0077132610604166985\n",
      "Epoch: 46500 0.008364644832909107\n",
      "Epoch: 46600 0.00812622532248497\n",
      "Epoch: 46700 0.011256923899054527\n",
      "Epoch: 46800 0.005123334936797619\n",
      "Epoch: 46900 0.005142593290656805\n",
      "Epoch: 47000 0.007046461571007967\n",
      "Epoch: 47100 0.006876359228044748\n",
      "Epoch: 47200 0.007567647844552994\n",
      "Epoch: 47300 0.008621369488537312\n",
      "Epoch: 47400 0.007946791127324104\n",
      "Epoch: 47500 0.007898086681962013\n",
      "Epoch: 47600 0.005471215583384037\n",
      "Epoch: 47700 0.010560382157564163\n",
      "Epoch: 47800 0.006081179715692997\n",
      "Epoch: 47900 0.015092320740222931\n",
      "Epoch: 48000 0.00553446589037776\n",
      "Epoch: 48100 0.004537921864539385\n",
      "Epoch: 48200 0.009274650365114212\n",
      "Epoch: 48300 0.009879713878035545\n",
      "Epoch: 48400 0.0075328052043914795\n",
      "Epoch: 48500 0.006673266179859638\n",
      "Epoch: 48600 0.004331440199166536\n",
      "Epoch: 48700 0.007303865626454353\n",
      "Epoch: 48800 0.007350300904363394\n",
      "Epoch: 48900 0.008200976997613907\n",
      "Epoch: 49000 0.0037118124309927225\n",
      "Epoch: 49100 0.013064269907772541\n",
      "Epoch: 49200 0.007722541689872742\n",
      "Epoch: 49300 0.00505657447502017\n",
      "Epoch: 49400 0.011983920820057392\n",
      "Epoch: 49500 0.012030946090817451\n",
      "Epoch: 49600 0.009024681523442268\n",
      "Epoch: 49700 0.004593790043145418\n",
      "Epoch: 49800 0.00755414878949523\n",
      "Epoch: 49900 0.005408504046499729\n",
      "Epoch: 50000 0.006760336458683014\n",
      "Epoch: 50100 0.008762294426560402\n",
      "Epoch: 50200 0.005917742382735014\n",
      "Epoch: 50300 0.005367019679397345\n",
      "Epoch: 50400 0.005219785962253809\n",
      "Epoch: 50500 0.00802855845540762\n",
      "Epoch: 50600 0.006202196702361107\n",
      "Epoch: 50700 0.005493157543241978\n",
      "Epoch: 50800 0.007820744067430496\n",
      "Epoch: 50900 0.006275072228163481\n",
      "Epoch: 51000 0.009226474910974503\n",
      "Epoch: 51100 0.0053580161184072495\n",
      "Epoch: 51200 0.005512859206646681\n",
      "Epoch: 51300 0.008862675167620182\n",
      "Epoch: 51400 0.005227141082286835\n",
      "Epoch: 51500 0.009648015722632408\n",
      "Epoch: 51600 0.004913878161460161\n",
      "Epoch: 51700 0.006515283137559891\n",
      "Epoch: 51800 0.004053265321999788\n",
      "Epoch: 51900 0.013505633920431137\n",
      "Epoch: 52000 0.006812720093876123\n",
      "Epoch: 52100 0.005742540583014488\n",
      "Epoch: 52200 0.011392916552722454\n",
      "Epoch: 52300 0.007066220045089722\n",
      "Epoch: 52400 0.008506761863827705\n",
      "Epoch: 52500 0.010391408577561378\n",
      "Epoch: 52600 0.006663523148745298\n",
      "Epoch: 52700 0.0067146881483495235\n",
      "Epoch: 52800 0.007311373483389616\n",
      "Epoch: 52900 0.004547406919300556\n",
      "Epoch: 53000 0.005673863925039768\n",
      "Epoch: 53100 0.007691171020269394\n",
      "Epoch: 53200 0.011247980408370495\n",
      "Epoch: 53300 0.0035182118881493807\n",
      "Epoch: 53400 0.007899022661149502\n",
      "Epoch: 53500 0.006152384448796511\n",
      "Epoch: 53600 0.006762189324945211\n",
      "Epoch: 53700 0.006791356485337019\n",
      "Epoch: 53800 0.006089685019105673\n",
      "Epoch: 53900 0.009089519269764423\n",
      "Epoch: 54000 0.008088259026408195\n",
      "Epoch: 54100 0.00632355734705925\n",
      "Epoch: 54200 0.006125649902969599\n",
      "Epoch: 54300 0.006065528839826584\n",
      "Epoch: 54400 0.008354783989489079\n",
      "Epoch: 54500 0.00844998937100172\n",
      "Epoch: 54600 0.005056571215391159\n",
      "Epoch: 54700 0.006720284931361675\n",
      "Epoch: 54800 0.005949205253273249\n",
      "Epoch: 54900 0.005065598990768194\n",
      "Epoch: 55000 0.00879831612110138\n",
      "Epoch: 55100 0.009745740331709385\n",
      "Epoch: 55200 0.005724803078919649\n",
      "Epoch: 55300 0.005519837606698275\n",
      "Epoch: 55400 0.006121646147221327\n",
      "Epoch: 55500 0.009200339205563068\n",
      "Epoch: 55600 0.009262432344257832\n",
      "Epoch: 55700 0.006776041816920042\n",
      "Epoch: 55800 0.004466730635613203\n",
      "Epoch: 55900 0.006441561970859766\n",
      "Epoch: 56000 0.00760458642616868\n",
      "Epoch: 56100 0.003696316620334983\n",
      "Epoch: 56200 0.003959656693041325\n",
      "Epoch: 56300 0.006487806793302298\n",
      "Epoch: 56400 0.009257077239453793\n",
      "Epoch: 56500 0.008394716307520866\n",
      "Epoch: 56600 0.00639707176014781\n",
      "Epoch: 56700 0.009432078339159489\n",
      "Epoch: 56800 0.009026347659528255\n",
      "Epoch: 56900 0.012135925702750683\n",
      "Epoch: 57000 0.0072580361738801\n",
      "Epoch: 57100 0.008037458173930645\n",
      "Epoch: 57200 0.009585787542164326\n",
      "Epoch: 57300 0.012490157969295979\n",
      "Epoch: 57400 0.009043675847351551\n",
      "Epoch: 57500 0.007536526303738356\n",
      "Epoch: 57600 0.008380843326449394\n",
      "Epoch: 57700 0.007594745606184006\n",
      "Epoch: 57800 0.007441071793437004\n",
      "Epoch: 57900 0.005082216113805771\n",
      "Epoch: 58000 0.005048589780926704\n",
      "Epoch: 58100 0.007314320188015699\n",
      "Epoch: 58200 0.0137826232239604\n",
      "Epoch: 58300 0.003188055008649826\n",
      "Epoch: 58400 0.006470945198088884\n",
      "Epoch: 58500 0.006637416779994965\n",
      "Epoch: 58600 0.004139424301683903\n",
      "Epoch: 58700 0.006051838397979736\n",
      "Epoch: 58800 0.00853642262518406\n",
      "Epoch: 58900 0.006018097512423992\n",
      "Epoch: 59000 0.008439251221716404\n",
      "Epoch: 59100 0.004620934370905161\n",
      "Epoch: 59200 0.006468665320426226\n",
      "Epoch: 59300 0.005075680557638407\n",
      "Epoch: 59400 0.005413651000708342\n",
      "Epoch: 59500 0.006299568340182304\n",
      "Epoch: 59600 0.004323209635913372\n",
      "Epoch: 59700 0.005803310312330723\n",
      "Epoch: 59800 0.005659284070134163\n",
      "Epoch: 59900 0.011372193694114685\n",
      "Epoch: 60000 0.00913196336477995\n",
      "Epoch: 60100 0.0062164789997041225\n",
      "Epoch: 60200 0.006924367044121027\n",
      "Epoch: 60300 0.007681743707507849\n",
      "Epoch: 60400 0.007760112173855305\n",
      "Epoch: 60500 0.006949210539460182\n",
      "Epoch: 60600 0.007350470870733261\n",
      "Epoch: 60700 0.003735258476808667\n",
      "Epoch: 60800 0.009894260205328465\n",
      "Epoch: 60900 0.005186089780181646\n",
      "Epoch: 61000 0.008006970398128033\n",
      "Epoch: 61100 0.005778248887509108\n",
      "Epoch: 61200 0.004322472959756851\n",
      "Epoch: 61300 0.005163500085473061\n",
      "Epoch: 61400 0.005635137669742107\n",
      "Epoch: 61500 0.007784872781485319\n",
      "Epoch: 61600 0.008677702397108078\n",
      "Epoch: 61700 0.008274419233202934\n",
      "Epoch: 61800 0.007798997685313225\n",
      "Epoch: 61900 0.010004453361034393\n",
      "Epoch: 62000 0.0078110480681061745\n",
      "Epoch: 62100 0.0037747167516499758\n",
      "Epoch: 62200 0.006278288085013628\n",
      "Epoch: 62300 0.010660453699529171\n",
      "Epoch: 62400 0.006983056198805571\n",
      "Epoch: 62500 0.005428897216916084\n",
      "Epoch: 62600 0.0039473529905080795\n",
      "Epoch: 62700 0.007728691678494215\n",
      "Epoch: 62800 0.004055304918438196\n",
      "Epoch: 62900 0.009373503737151623\n",
      "Epoch: 63000 0.009588516317307949\n",
      "Epoch: 63100 0.00759407551959157\n",
      "Epoch: 63200 0.008891338482499123\n",
      "Epoch: 63300 0.008675445802509785\n",
      "Epoch: 63400 0.006492592394351959\n",
      "Epoch: 63500 0.007898053154349327\n",
      "Epoch: 63600 0.0070360805839300156\n",
      "Epoch: 63700 0.006400057580322027\n",
      "Epoch: 63800 0.00289329094812274\n",
      "Epoch: 63900 0.01550330501049757\n",
      "Epoch: 64000 0.008771141059696674\n",
      "Epoch: 64100 0.003833689261227846\n",
      "Epoch: 64200 0.00444453489035368\n",
      "Epoch: 64300 0.0061085522174835205\n",
      "Epoch: 64400 0.006471041589975357\n",
      "Epoch: 64500 0.006905444897711277\n",
      "Epoch: 64600 0.009021597914397717\n",
      "Epoch: 64700 0.007044526282697916\n",
      "Epoch: 64800 0.014215870760381222\n",
      "Epoch: 64900 0.006909582763910294\n",
      "Epoch: 65000 0.007105616852641106\n",
      "Epoch: 65100 0.008233778178691864\n",
      "Epoch: 65200 0.006910590920597315\n",
      "Epoch: 65300 0.005126475356519222\n",
      "Epoch: 65400 0.00602232338860631\n",
      "Epoch: 65500 0.005447509232908487\n",
      "Epoch: 65600 0.004962523002177477\n",
      "Epoch: 65700 0.004252389073371887\n",
      "Epoch: 65800 0.00671022804453969\n",
      "Epoch: 65900 0.00497260270640254\n",
      "Epoch: 66000 0.011340743862092495\n",
      "Epoch: 66100 0.0066393157467246056\n",
      "Epoch: 66200 0.0048372019082307816\n",
      "Epoch: 66300 0.013100146315991879\n",
      "Epoch: 66400 0.007034738548099995\n",
      "Epoch: 66500 0.005767337046563625\n",
      "Epoch: 66600 0.007093184627592564\n",
      "Epoch: 66700 0.004172490909695625\n",
      "Epoch: 66800 0.0043707373552024364\n",
      "Epoch: 66900 0.005498319398611784\n",
      "Epoch: 67000 0.0047518485225737095\n",
      "Epoch: 67100 0.006296454928815365\n",
      "Epoch: 67200 0.007256024517118931\n",
      "Epoch: 67300 0.006690625101327896\n",
      "Epoch: 67400 0.004737937822937965\n",
      "Epoch: 67500 0.012214471586048603\n",
      "Epoch: 67600 0.004470448475331068\n",
      "Epoch: 67700 0.00787411630153656\n",
      "Epoch: 67800 0.005585703067481518\n",
      "Epoch: 67900 0.006732643581926823\n",
      "Epoch: 68000 0.008291141130030155\n",
      "Epoch: 68100 0.004594915546476841\n",
      "Epoch: 68200 0.0057663884945213795\n",
      "Epoch: 68300 0.00712446216493845\n",
      "Epoch: 68400 0.0072228978388011456\n",
      "Epoch: 68500 0.007644388359040022\n",
      "Epoch: 68600 0.005247377324849367\n",
      "Epoch: 68700 0.0072614760138094425\n",
      "Epoch: 68800 0.008945866487920284\n",
      "Epoch: 68900 0.0055460440926253796\n",
      "Epoch: 69000 0.004327788483351469\n",
      "Epoch: 69100 0.005218713544309139\n",
      "Epoch: 69200 0.0070550041273236275\n",
      "Epoch: 69300 0.0057455627247691154\n",
      "Epoch: 69400 0.003651075065135956\n",
      "Epoch: 69500 0.005838540382683277\n",
      "Epoch: 69600 0.0075604477897286415\n",
      "Epoch: 69700 0.008884470909833908\n",
      "Epoch: 69800 0.0043054502457380295\n",
      "Epoch: 69900 0.007379342336207628\n",
      "Epoch: 70000 0.006416936405003071\n",
      "Epoch: 70100 0.005016160197556019\n",
      "Epoch: 70200 0.003529721638187766\n",
      "Epoch: 70300 0.005749676376581192\n",
      "Epoch: 70400 0.0116463303565979\n",
      "Epoch: 70500 0.006957529578357935\n",
      "Epoch: 70600 0.006570738274604082\n",
      "Epoch: 70700 0.00477228919044137\n",
      "Epoch: 70800 0.00493680639192462\n",
      "Epoch: 70900 0.006789075676351786\n",
      "Epoch: 71000 0.007082314696162939\n",
      "Epoch: 71100 0.004938129335641861\n",
      "Epoch: 71200 0.005798207595944405\n",
      "Epoch: 71300 0.00699958810582757\n",
      "Epoch: 71400 0.009611583314836025\n",
      "Epoch: 71500 0.0048184264451265335\n",
      "Epoch: 71600 0.012818945571780205\n",
      "Epoch: 71700 0.005421248264610767\n",
      "Epoch: 71800 0.007413693703711033\n",
      "Epoch: 71900 0.008913201279938221\n",
      "Epoch: 72000 0.005257974844425917\n",
      "Epoch: 72100 0.01177275087684393\n",
      "Epoch: 72200 0.0073448047041893005\n",
      "Epoch: 72300 0.007705753203481436\n",
      "Epoch: 72400 0.004947510082274675\n",
      "Epoch: 72500 0.007309097331017256\n",
      "Epoch: 72600 0.005536240059882402\n",
      "Epoch: 72700 0.0047779749147593975\n",
      "Epoch: 72800 0.007915930822491646\n",
      "Epoch: 72900 0.005184368696063757\n",
      "Epoch: 73000 0.005041994620114565\n",
      "Epoch: 73100 0.006434938404709101\n",
      "Epoch: 73200 0.005175715312361717\n",
      "Epoch: 73300 0.006395143456757069\n",
      "Epoch: 73400 0.00848231092095375\n",
      "Epoch: 73500 0.007098096888512373\n",
      "Epoch: 73600 0.0037714557256549597\n",
      "Epoch: 73700 0.0039884778670966625\n",
      "Epoch: 73800 0.004969215486198664\n",
      "Epoch: 73900 0.0049681346863508224\n",
      "Epoch: 74000 0.014137578196823597\n",
      "Epoch: 74100 0.005560910329222679\n",
      "Epoch: 74200 0.005712343845516443\n",
      "Epoch: 74300 0.005598165560513735\n",
      "Epoch: 74400 0.006462425924837589\n",
      "Epoch: 74500 0.0037905871868133545\n",
      "Epoch: 74600 0.005173287820070982\n",
      "Epoch: 74700 0.004434259608387947\n",
      "Epoch: 74800 0.0034417591523379087\n",
      "Epoch: 74900 0.0063778795301914215\n",
      "Epoch: 75000 0.0036002330016344786\n",
      "Epoch: 75100 0.003933100961148739\n",
      "Epoch: 75200 0.007786172442138195\n",
      "Epoch: 75300 0.0072006951086223125\n",
      "Epoch: 75400 0.004704040940850973\n",
      "Epoch: 75500 0.006232303101569414\n",
      "Epoch: 75600 0.00841443333774805\n",
      "Epoch: 75700 0.004966012202203274\n",
      "Epoch: 75800 0.011065357364714146\n",
      "Epoch: 75900 0.0039729708805680275\n",
      "Epoch: 76000 0.006894433870911598\n",
      "Epoch: 76100 0.005548839457333088\n",
      "Epoch: 76200 0.008881074376404285\n",
      "Epoch: 76300 0.014637759886682034\n",
      "Epoch: 76400 0.006530749145895243\n",
      "Epoch: 76500 0.008083412423729897\n",
      "Epoch: 76600 0.004861147608608007\n",
      "Epoch: 76700 0.006940729916095734\n",
      "Epoch: 76800 0.005460618529468775\n",
      "Epoch: 76900 0.0066970703192055225\n",
      "Epoch: 77000 0.006173723377287388\n",
      "Epoch: 77100 0.010733415372669697\n",
      "Epoch: 77200 0.010536410845816135\n",
      "Epoch: 77300 0.006770330015569925\n",
      "Epoch: 77400 0.008057882077991962\n",
      "Epoch: 77500 0.0047383904457092285\n",
      "Epoch: 77600 0.004266217816621065\n",
      "Epoch: 77700 0.004555512219667435\n",
      "Epoch: 77800 0.004626153968274593\n",
      "Epoch: 77900 0.0057156262919306755\n",
      "Epoch: 78000 0.00809435173869133\n",
      "Epoch: 78100 0.008759272284805775\n",
      "Epoch: 78200 0.0049797832034528255\n",
      "Epoch: 78300 0.005512839648872614\n",
      "Epoch: 78400 0.006965581327676773\n",
      "Epoch: 78500 0.00862424261868\n",
      "Epoch: 78600 0.005550062749534845\n",
      "Epoch: 78700 0.007195166312158108\n",
      "Epoch: 78800 0.004563779104501009\n",
      "Epoch: 78900 0.005052444525063038\n",
      "Epoch: 79000 0.008822924457490444\n",
      "Epoch: 79100 0.00751923443749547\n",
      "Epoch: 79200 0.0066826059482991695\n",
      "Epoch: 79300 0.008965548127889633\n",
      "Epoch: 79400 0.006406471133232117\n",
      "Epoch: 79500 0.005592614412307739\n",
      "Epoch: 79600 0.005492666736245155\n",
      "Epoch: 79700 0.0072791059501469135\n",
      "Epoch: 79800 0.006803164258599281\n",
      "Epoch: 79900 0.009418199770152569\n",
      "Epoch: 80000 0.005557652562856674\n",
      "Epoch: 80100 0.0028344697784632444\n",
      "Epoch: 80200 0.012966097332537174\n",
      "Epoch: 80300 0.00484619801864028\n",
      "Epoch: 80400 0.004623460583388805\n",
      "Epoch: 80500 0.0043783183209598064\n",
      "Epoch: 80600 0.005835844669491053\n",
      "Epoch: 80700 0.0057050324976444244\n",
      "Epoch: 80800 0.005698605440557003\n",
      "Epoch: 80900 0.009181803092360497\n",
      "Epoch: 81000 0.008940961211919785\n",
      "Epoch: 81100 0.005941741168498993\n",
      "Epoch: 81200 0.009700819849967957\n",
      "Epoch: 81300 0.006520989816635847\n",
      "Epoch: 81400 0.00685901241376996\n",
      "Epoch: 81500 0.002658615820109844\n",
      "Epoch: 81600 0.009139398112893105\n",
      "Epoch: 81700 0.007035566493868828\n",
      "Epoch: 81800 0.0043688565492630005\n",
      "Epoch: 81900 0.006745999678969383\n",
      "Epoch: 82000 0.005860912147909403\n",
      "Epoch: 82100 0.005865130573511124\n",
      "Epoch: 82200 0.0030082378070801497\n",
      "Epoch: 82300 0.006612411700189114\n",
      "Epoch: 82400 0.007823101244866848\n",
      "Epoch: 82500 0.003481751773506403\n",
      "Epoch: 82600 0.003655108856037259\n",
      "Epoch: 82700 0.005388396792113781\n",
      "Epoch: 82800 0.0053263017907738686\n",
      "Epoch: 82900 0.006137362215667963\n",
      "Epoch: 83000 0.007166022434830666\n",
      "Epoch: 83100 0.003557003103196621\n",
      "Epoch: 83200 0.004235825967043638\n",
      "Epoch: 83300 0.004906520247459412\n",
      "Epoch: 83400 0.0035697876010090113\n",
      "Epoch: 83500 0.00593839306384325\n",
      "Epoch: 83600 0.004653761629015207\n",
      "Epoch: 83700 0.004940844606608152\n",
      "Epoch: 83800 0.006847926881164312\n",
      "Epoch: 83900 0.007428931072354317\n",
      "Epoch: 84000 0.013285942375659943\n",
      "Epoch: 84100 0.0038636394310742617\n",
      "Epoch: 84200 0.004860360641032457\n",
      "Epoch: 84300 0.004706976469606161\n",
      "Epoch: 84400 0.004342956002801657\n",
      "Epoch: 84500 0.005097511690109968\n",
      "Epoch: 84600 0.005962874740362167\n",
      "Epoch: 84700 0.006159279961138964\n",
      "Epoch: 84800 0.007505364716053009\n",
      "Epoch: 84900 0.006669194437563419\n",
      "Epoch: 85000 0.005425971932709217\n",
      "Epoch: 85100 0.0064627742394804955\n",
      "Epoch: 85200 0.006162539124488831\n",
      "Epoch: 85300 0.00667705899104476\n",
      "Epoch: 85400 0.005655860994011164\n",
      "Epoch: 85500 0.00760707026347518\n",
      "Epoch: 85600 0.0035755836870521307\n",
      "Epoch: 85700 0.005318767856806517\n",
      "Epoch: 85800 0.005617303773760796\n",
      "Epoch: 85900 0.006198199465870857\n",
      "Epoch: 86000 0.006045629270374775\n",
      "Epoch: 86100 0.004263194743543863\n",
      "Epoch: 86200 0.004344094078987837\n",
      "Epoch: 86300 0.003618816612288356\n",
      "Epoch: 86400 0.0033719507046043873\n",
      "Epoch: 86500 0.006572343874722719\n",
      "Epoch: 86600 0.006908887065947056\n",
      "Epoch: 86700 0.006795726250857115\n",
      "Epoch: 86800 0.005938859190791845\n",
      "Epoch: 86900 0.005203512031584978\n",
      "Epoch: 87000 0.004263491835445166\n",
      "Epoch: 87100 0.008210824802517891\n",
      "Epoch: 87200 0.007725595496594906\n",
      "Epoch: 87300 0.005502615589648485\n",
      "Epoch: 87400 0.0075468337163329124\n",
      "Epoch: 87500 0.004052563104778528\n",
      "Epoch: 87600 0.006155272945761681\n",
      "Epoch: 87700 0.005055339075624943\n",
      "Epoch: 87800 0.004402213264256716\n",
      "Epoch: 87900 0.0050627258606255054\n",
      "Epoch: 88000 0.0060086846351623535\n",
      "Epoch: 88100 0.0033077113330364227\n",
      "Epoch: 88200 0.008404403924942017\n",
      "Epoch: 88300 0.0032222922891378403\n",
      "Epoch: 88400 0.006324928253889084\n",
      "Epoch: 88500 0.00967775471508503\n",
      "Epoch: 88600 0.004361727274954319\n",
      "Epoch: 88700 0.004729417618364096\n",
      "Epoch: 88800 0.00580601766705513\n",
      "Epoch: 88900 0.007534849923104048\n",
      "Epoch: 89000 0.006035552825778723\n",
      "Epoch: 89100 0.004400019999593496\n",
      "Epoch: 89200 0.005333133973181248\n",
      "Epoch: 89300 0.00514058256521821\n",
      "Epoch: 89400 0.005339549854397774\n",
      "Epoch: 89500 0.00585802411660552\n",
      "Epoch: 89600 0.003296040929853916\n",
      "Epoch: 89700 0.004891539923846722\n",
      "Epoch: 89800 0.008980842307209969\n",
      "Epoch: 89900 0.0070721544325351715\n",
      "Epoch: 90000 0.007152730133384466\n",
      "Epoch: 90100 0.007236765697598457\n",
      "Epoch: 90200 0.006272987928241491\n",
      "Epoch: 90300 0.004778530448675156\n",
      "Epoch: 90400 0.006090353708714247\n",
      "Epoch: 90500 0.00277868565171957\n",
      "Epoch: 90600 0.006303159520030022\n",
      "Epoch: 90700 0.008643088862299919\n",
      "Epoch: 90800 0.0036094391252845526\n",
      "Epoch: 90900 0.004488608334213495\n",
      "Epoch: 91000 0.0038289648946374655\n",
      "Epoch: 91100 0.003392864251509309\n",
      "Epoch: 91200 0.006240932270884514\n",
      "Epoch: 91300 0.0037680366076529026\n",
      "Epoch: 91400 0.004979343619197607\n",
      "Epoch: 91500 0.007436790037900209\n",
      "Epoch: 91600 0.00930970162153244\n",
      "Epoch: 91700 0.009757241234183311\n",
      "Epoch: 91800 0.004969300702214241\n",
      "Epoch: 91900 0.007952284067869186\n",
      "Epoch: 92000 0.005757248494774103\n",
      "Epoch: 92100 0.005414788611233234\n",
      "Epoch: 92200 0.0032099538948386908\n",
      "Epoch: 92300 0.004865693394094706\n",
      "Epoch: 92400 0.0066786096431314945\n",
      "Epoch: 92500 0.003146288450807333\n",
      "Epoch: 92600 0.004592275712639093\n",
      "Epoch: 92700 0.004539058078080416\n",
      "Epoch: 92800 0.006697496864944696\n",
      "Epoch: 92900 0.0074624004773795605\n",
      "Epoch: 93000 0.0045207468792796135\n",
      "Epoch: 93100 0.007939839735627174\n",
      "Epoch: 93200 0.004078976344317198\n",
      "Epoch: 93300 0.006057179998606443\n",
      "Epoch: 93400 0.008398699574172497\n",
      "Epoch: 93500 0.012602678500115871\n",
      "Epoch: 93600 0.006043953355401754\n",
      "Epoch: 93700 0.0035384956281632185\n",
      "Epoch: 93800 0.007234134245663881\n",
      "Epoch: 93900 0.011472768150269985\n",
      "Epoch: 94000 0.003212185576558113\n",
      "Epoch: 94100 0.004938056226819754\n",
      "Epoch: 94200 0.008070763200521469\n",
      "Epoch: 94300 0.007883676327764988\n",
      "Epoch: 94400 0.0027529653161764145\n",
      "Epoch: 94500 0.008980215527117252\n",
      "Epoch: 94600 0.0063965702429413795\n",
      "Epoch: 94700 0.0044179633259773254\n",
      "Epoch: 94800 0.0044485656544566154\n",
      "Epoch: 94900 0.01046808809041977\n",
      "Epoch: 95000 0.005662384442985058\n",
      "Epoch: 95100 0.008006586693227291\n",
      "Epoch: 95200 0.006916492246091366\n",
      "Epoch: 95300 0.0055633126758039\n",
      "Epoch: 95400 0.00477816304191947\n",
      "Epoch: 95500 0.005936930887401104\n",
      "Epoch: 95600 0.003938487730920315\n",
      "Epoch: 95700 0.008232349529862404\n",
      "Epoch: 95800 0.004507952835410833\n",
      "Epoch: 95900 0.003153617260977626\n",
      "Epoch: 96000 0.009504160843789577\n",
      "Epoch: 96100 0.00496384222060442\n",
      "Epoch: 96200 0.005252063740044832\n",
      "Epoch: 96300 0.003226909087970853\n",
      "Epoch: 96400 0.003732097102329135\n",
      "Epoch: 96500 0.006215962581336498\n",
      "Epoch: 96600 0.0033373504411429167\n",
      "Epoch: 96700 0.002704496728256345\n",
      "Epoch: 96800 0.004819450434297323\n",
      "Epoch: 96900 0.004060536157339811\n",
      "Epoch: 97000 0.004766752943396568\n",
      "Epoch: 97100 0.0025743087753653526\n",
      "Epoch: 97200 0.0030844116117805243\n",
      "Epoch: 97300 0.0018315546913072467\n",
      "Epoch: 97400 0.005636768881231546\n",
      "Epoch: 97500 0.0046692099422216415\n",
      "Epoch: 97600 0.004832417704164982\n",
      "Epoch: 97700 0.004269915167242289\n",
      "Epoch: 97800 0.009274845942854881\n",
      "Epoch: 97900 0.0075628734193742275\n",
      "Epoch: 98000 0.004547870717942715\n",
      "Epoch: 98100 0.0037522288039326668\n",
      "Epoch: 98200 0.0032588259782642126\n",
      "Epoch: 98300 0.0037754515651613474\n",
      "Epoch: 98400 0.005975387059152126\n",
      "Epoch: 98500 0.00632967334240675\n",
      "Epoch: 98600 0.006199135910719633\n",
      "Epoch: 98700 0.0035149862524122\n",
      "Epoch: 98800 0.004766656085848808\n",
      "Epoch: 98900 0.012408158741891384\n",
      "Epoch: 99000 0.004788857419043779\n",
      "Epoch: 99100 0.006843443959951401\n",
      "Epoch: 99200 0.008836520835757256\n",
      "Epoch: 99300 0.0057389819994568825\n",
      "Epoch: 99400 0.008196036331355572\n",
      "Epoch: 99500 0.009030451066792011\n",
      "Epoch: 99600 0.011675546877086163\n",
      "Epoch: 99700 0.0032376067247241735\n",
      "Epoch: 99800 0.008200140669941902\n",
      "Epoch: 99900 0.006111676339060068\n"
     ]
    }
   ],
   "source": [
    "def conditional_flow_matching_loss(flow_model, x):\n",
    "    #Question: Should we calculate one for each time step or generate one time at a time?\n",
    "    \n",
    "    sigma_min = 1e-4\n",
    "    t = torch.rand(x.shape[0], device=x.device).unsqueeze(-1)\n",
    "    noise = torch.randn_like(x).to(x.device)\n",
    "\n",
    "    x_t = (1 - (1 - sigma_min) * t) * noise + t* x\n",
    "    optimal_flow = x - (1 - sigma_min) * noise\n",
    "    predicted_flow = flow_model(x_t, t)\n",
    "\n",
    "    return (predicted_flow - optimal_flow).square().mean()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SE3VelocityField().to(device)\n",
    "x = grasp_T[:, :3, 3]\n",
    "x_train = x.repeat(1000, 1).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(100000):\n",
    "    model.zero_grad()\n",
    "    loss = conditional_flow_matching_loss(model,x_train)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch}',loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8406c0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2271, -0.1689,  0.1003]], grad_fn=<SelectBackward0>) tensor([[-0.2228, -0.1666,  0.1002]])\n"
     ]
    }
   ],
   "source": [
    "def run_flow(flow_model, x_0, steps=100, device='cuda'):\n",
    "    t = torch.linspace(0, 1, steps).to(device)\n",
    "    def ode_func(t, x):\n",
    "        # Reshape t to match model input expectations\n",
    "        t_batch = torch.full((x.shape[0], 1), t.item(), device=device)\n",
    "        return flow_model(x, t_batch)\n",
    "    # Integrate from t=0 to t=1\n",
    "    trajectory = odeint(\n",
    "        ode_func,\n",
    "        x_0,\n",
    "        t,\n",
    "        method='rk4'  # You can also try 'dopri5' for adaptive stepping\n",
    "    )\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "noise = torch.randn_like(grasp_T[:,:3,3]).to(device)\n",
    "trajectory = run_flow(model, noise, steps=100, device=device)\n",
    "print(trajectory[-1],grasp_T[:,:3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level groups: ['grasps', 'gripper', 'object']\n",
      "\n",
      "Exploring complete structure:\n",
      "\n",
      "=== grasps ===\n",
      "Group: qualities\n",
      "  Contents: ['flex']\n",
      "  Group: flex\n",
      "    Contents: ['object_in_gripper', 'object_motion_during_closing_angular', 'object_motion_during_closing_linear', 'object_motion_during_shaking_angular', 'object_motion_during_shaking_linear']\n",
      "    Dataset: object_in_gripper\n",
      "      Shape: (2000,)\n",
      "      Type: int64\n",
      "      First few values: [1 1]\n",
      "    Dataset: object_motion_during_closing_angular\n",
      "      Shape: (2000,)\n",
      "      Type: float64\n",
      "      First few values: [0.54927611 0.15047622]\n",
      "    Dataset: object_motion_during_closing_linear\n",
      "      Shape: (2000,)\n",
      "      Type: float64\n",
      "      First few values: [0.09023842 0.02939418]\n",
      "    Dataset: object_motion_during_shaking_angular\n",
      "      Shape: (2000,)\n",
      "      Type: float64\n",
      "      First few values: [0.0185062  0.04676599]\n",
      "    Dataset: object_motion_during_shaking_linear\n",
      "      Shape: (2000,)\n",
      "      Type: float64\n",
      "      First few values: [0.00300531 0.00718987]\n",
      "Dataset: transforms\n",
      "  Shape: (2000, 4, 4)\n",
      "  Type: float64\n",
      "  First few values: [[[-0.38083587 -0.32743824  0.86472437 -0.22282051]\n",
      "  [-0.14879235  0.94471263  0.29219666 -0.16660974]\n",
      "  [-0.91259239 -0.01738541 -0.40850076  0.10019681]\n",
      "  [ 0.          0.          0.          1.        ]]\n",
      "\n",
      " [[-0.38083587  0.14879235  0.91259239 -0.22760731]\n",
      "  [-0.14879235  0.96424346 -0.21930658 -0.11545942]\n",
      "  [-0.91259239 -0.21930658 -0.34507934  0.09385467]\n",
      "  [ 0.          0.          0.          1.        ]]]\n",
      "\n",
      "=== gripper ===\n",
      "Dataset: configuration\n",
      "  Shape: (1,)\n",
      "  Type: float64\n",
      "  First few values: [0.04]\n",
      "Dataset: type\n",
      "  Shape: ()\n",
      "  Type: object\n",
      "  Could not print values: Illegal slicing argument for scalar dataspace\n",
      "\n",
      "=== object ===\n",
      "Dataset: com\n",
      "  Shape: (3,)\n",
      "  Type: float64\n",
      "  First few values: [-0.01902643 -0.15787416]\n",
      "Dataset: density\n",
      "  Shape: ()\n",
      "  Type: float64\n",
      "  Could not print values: Illegal slicing argument for scalar dataspace\n",
      "Dataset: file\n",
      "  Shape: ()\n",
      "  Type: object\n",
      "  Could not print values: Illegal slicing argument for scalar dataspace\n",
      "Dataset: friction\n",
      "  Shape: ()\n",
      "  Type: float64\n",
      "  Could not print values: Illegal slicing argument for scalar dataspace\n",
      "Dataset: inertia\n",
      "  Shape: (3, 3)\n",
      "  Type: float64\n",
      "  First few values: [[6.797040e-05 1.622000e-07 5.730000e-08]\n",
      " [1.622000e-07 4.103991e-04 1.040000e-08]]\n",
      "Dataset: mass\n",
      "  Shape: ()\n",
      "  Type: float64\n",
      "  Could not print values: Illegal slicing argument for scalar dataspace\n",
      "Dataset: scale\n",
      "  Shape: ()\n",
      "  Type: float64\n",
      "  Could not print values: Illegal slicing argument for scalar dataspace\n",
      "Dataset: volume\n",
      "  Shape: ()\n",
      "  Type: float64\n",
      "  Could not print values: Illegal slicing argument for scalar dataspace\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def explore_group(group, indent=\"\"):\n",
    "    \"\"\"Recursively explore an HDF5 group and its contents\"\"\"\n",
    "    for name, item in group.items():\n",
    "        if isinstance(item, h5py.Group):\n",
    "            print(f\"{indent}Group: {name}\")\n",
    "            print(f\"{indent}  Contents: {list(item.keys())}\")\n",
    "            explore_group(item, indent + \"  \")\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            print(f\"{indent}Dataset: {name}\")\n",
    "            print(f\"{indent}  Shape: {item.shape}\")\n",
    "            print(f\"{indent}  Type: {item.dtype}\")\n",
    "            try:\n",
    "                print(f\"{indent}  First few values: {item[:2]}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{indent}  Could not print values: {e}\")\n",
    "\n",
    "with h5py.File(example_grasp, 'r') as h5file:\n",
    "    print(\"Top-level groups:\", list(h5file.keys()))\n",
    "    \n",
    "    print(\"\\nExploring complete structure:\")\n",
    "    for top_group_name in h5file.keys():\n",
    "        print(f\"\\n=== {top_group_name} ===\")\n",
    "        top_group = h5file[top_group_name]\n",
    "        explore_group(top_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546571f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
